{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S0eQ0Gj9QFJW"
   },
   "source": [
    "# Import Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JfF1AmA3QDGF"
   },
   "outputs": [],
   "source": [
    "import torch, os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import scipy\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from scipy.ndimage import rotate\n",
    "from random import randint\n",
    "from pathlib import Path\n",
    "\n",
    "def rm_tree(pth):\n",
    "    pth = Path(pth)\n",
    "    for child in pth.glob('*'):\n",
    "        if child.is_file():\n",
    "            child.unlink()\n",
    "        else:\n",
    "            rm_tree(child)\n",
    "    pth.rmdir()\n",
    "\n",
    "def fg_ratio(mask):\n",
    "    if torch.is_tensor(mask):\n",
    "        mask = mask.numpy()\n",
    "    return np.count_nonzero(mask) / np.count_nonzero(np.ones_like(mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rcTE-6Q9X-P5"
   },
   "source": [
    "# Helper func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tvgFe7gTRHb9"
   },
   "outputs": [],
   "source": [
    "def rotate3d(volume, degree):\n",
    "    \"\"\"volume shape: numpy array (D, H, W)\"\"\"\n",
    "    rotated_volume = np.zeros_like(volume)\n",
    "    for i in range(volume.shape[0]):\n",
    "        rotated_volume[i] = rotate(volume[i], degree, reshape=False)\n",
    "    return rotated_volume\n",
    "\n",
    "def crop_center_3d(mask, output_size=(14, 110, 110)):\n",
    "    if len(mask.shape) == 5: # b, c, d, h, w\n",
    "        d, h, w = mask.shape[2:]\n",
    "    elif len(mask.shape) == 3: # d, h, w\n",
    "        d, h, w = mask.shape\n",
    "\n",
    "    start_d = (d - output_size[0]) // 2\n",
    "    start_h = (h - output_size[1]) // 2\n",
    "    start_w = (w - output_size[2]) // 2\n",
    "    return mask[..., start_d:(start_d + output_size[0]), start_h:(start_h + output_size[1]), start_w:(start_w + output_size[2])]\n",
    "    \n",
    "def elastic_transform_3d(image, mask, alpha, sigma, alpha_affine=-1, random_state=None):\n",
    "    \"\"\"\n",
    "    Param:\n",
    "        image (np.ndarray): image to be deformed\n",
    "        alpha (float): scale of transformation for each dimension, where larger\n",
    "            values have more deformation\n",
    "        sigma (float): Gaussian window of deformation for each dimension, where\n",
    "            smaller values have more localised deformation\n",
    "    Returns:\n",
    "        np.ndarray: deformed image\n",
    "    \"\"\"\n",
    "    ori_shape = image.shape\n",
    "\n",
    "    if len(ori_shape) < 3:\n",
    "        image = np.expand_dims(image, axis=-1)\n",
    "        mask = np.expand_dims(mask, axis=-1)\n",
    "    \n",
    "    if random_state is None:\n",
    "        seed = randint(1, 200)\n",
    "        random_state = np.random.RandomState(seed)\n",
    "    \n",
    "    shape = image.shape\n",
    "    \n",
    "    # Random affine\n",
    "    if alpha_affine > 0:\n",
    "        # print('affine')\n",
    "        shape_size = shape[:2]\n",
    "        center_square = np.float32(shape_size) // 2\n",
    "        square_size = min(shape_size) // 3\n",
    "        pts1 = np.float32([center_square + square_size, [center_square[0]+square_size, center_square[1]-square_size], center_square - square_size])\n",
    "        pts2 = pts1 + random_state.uniform(-alpha_affine, alpha_affine, size=pts1.shape).astype(np.float32)\n",
    "        M = cv2.getAffineTransform(pts1, pts2)\n",
    "        image = cv2.warpAffine(image, M, shape_size[::-1], borderMode=cv2.BORDER_REFLECT_101)\n",
    "        mask = cv2.warpAffine(mask, M, shape_size[::-1], borderMode=cv2.BORDER_REFLECT_101)\n",
    "\n",
    "        if len(image.shape) < 3:\n",
    "            image = np.expand_dims(image, axis=-1)\n",
    "            mask = np.expand_dims(mask, axis=-1)\n",
    "\n",
    "    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"reflect\", cval=0) * alpha\n",
    "    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"reflect\", cval=0) * alpha\n",
    "    dz = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"reflect\", cval=0) * alpha * shape[2]/shape[0]\n",
    "\n",
    "    x, y, z = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]), np.arange(shape[2]))\n",
    "    indices = np.reshape(y+dy, (-1, 1)), np.reshape(x+dx, (-1, 1)), np.reshape(z+dz, (-1, 1))\n",
    "\n",
    "    image_trans = map_coordinates(image, indices, order=1, mode='reflect').reshape(ori_shape)\n",
    "    mask_trans = map_coordinates(mask, indices, order=1, mode='reflect').reshape(ori_shape)\n",
    "    return image_trans, mask_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4O3XwTBCNa5M"
   },
   "source": [
    "# Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TmxjhT-uD6VP"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def aug_data(volume, mask):\n",
    "    #make a copy\n",
    "    aug_volume = np.array(volume, dtype=np.float32)\n",
    "    aug_mask = np.array(mask, dtype=np.uint8)\n",
    "\n",
    "    #Random rotation x y\n",
    "    if random.uniform(0, 1) < ROTATE_PROB and MAX_ROTATE_ANGLE_X > 0.:\n",
    "        rotate_angle = random.uniform(-MAX_ROTATE_ANGLE_X, MAX_ROTATE_ANGLE_X)\n",
    "        aug_volume = scipy.ndimage.interpolation.rotate(aug_volume, rotate_angle, (0,2), reshape = False, mode = 'nearest')\n",
    "        aug_mask = scipy.ndimage.interpolation.rotate(aug_mask, rotate_angle, (0,2), reshape = False, mode = 'nearest')\n",
    "        # print('\\t+ Random rotation x')\n",
    "\n",
    "    if random.uniform(0, 1) < ROTATE_PROB and MAX_ROTATE_ANGLE_Y > 0.:\n",
    "        rotate_angle = random.uniform(-MAX_ROTATE_ANGLE_Y, MAX_ROTATE_ANGLE_Y)\n",
    "        aug_volume = scipy.ndimage.interpolation.rotate(aug_volume, rotate_angle, (0, 1), reshape=False, mode='nearest')\n",
    "        aug_mask = scipy.ndimage.interpolation.rotate(aug_mask, rotate_angle, (0, 1), reshape=False, mode='nearest')\n",
    "        # print('\\t+ Random rotation y')\n",
    "    \n",
    "    # Random rotation z\n",
    "    if random.uniform(0, 1) < ROTATE_PROB and MAX_ROTATE_ANGLE_Z > 0.:\n",
    "        rotate_angle = random.uniform(-MAX_ROTATE_ANGLE_Z, MAX_ROTATE_ANGLE_Z)\n",
    "        aug_volume = scipy.ndimage.interpolation.rotate(aug_volume, rotate_angle,(1,2), reshape=False, mode='nearest')\n",
    "        aug_mask = scipy.ndimage.interpolation.rotate(aug_mask, rotate_angle,(1,2), reshape=False, mode='nearest')\n",
    "        # print('\\t+ Random rotation z')\n",
    "\n",
    "    # Elastic Transform\n",
    "    if random.uniform(0, 1) < ELASTIC_PROB:\n",
    "        # Change D H W to H W D\n",
    "        aug_volume = np.moveaxis(aug_volume, 0, -1)\n",
    "        aug_mask = np.moveaxis(aug_mask, 0, -1)\n",
    "        alpha_factor = 2\n",
    "        sigma_factor = 0.08\n",
    "        alpha_affine_factor = 0.08\n",
    "\n",
    "        # print(aug_mask.shape, aug_mask.shape)\n",
    "        aug_volume, aug_mask = elastic_transform_3d(aug_volume, aug_mask, alpha = aug_volume.shape[1] * alpha_factor, sigma = aug_volume.shape[1] * sigma_factor, alpha_affine = aug_volume.shape[1] * alpha_affine_factor)\n",
    "        # Change H W D to D H W\n",
    "        aug_volume = np.moveaxis(aug_volume, -1, 0)\n",
    "        aug_mask = np.moveaxis(aug_mask, -1, 0)\n",
    "        # print('\\t+ Elastic Transform Perform')\n",
    "\n",
    "    # Normalize\n",
    "    aug_volume[aug_volume<0.] = 0.\n",
    "    aug_volume[aug_volume>1.] = 1.\n",
    "    aug_mask[aug_mask>=0.5] = 1\n",
    "    aug_mask[aug_mask<0.5] = 0\n",
    "\n",
    "    return aug_volume, aug_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bvO4O44JpqoA"
   },
   "source": [
    "# get patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VURGd-rh3Zc9"
   },
   "outputs": [],
   "source": [
    "def generate_patches(volume, mask, size=(1, 128, 128), stride=(1, 120, 120), padding=True, remove=True, percent=0.01):\n",
    "    \"\"\"\n",
    "    volume, mask: numpy array (D, H, W)\n",
    "    size: shape of an output patch \n",
    "    @return numpy array (n, c, h, w) or (n, 1, d, h, w)\n",
    "    \"\"\"\n",
    "    assert volume.shape == mask.shape, 'Shape of volume and mask are different'\n",
    "    assert len(volume.shape) == 3, 'Invalid volume shape'\n",
    "    remove_patch = 0\n",
    "    if len(size) == 4:\n",
    "        ch, size_d, size_h, size_w = size\n",
    "    elif len(size) == 3:\n",
    "        ch, size_h, size_w = size\n",
    "        size_d = ch\n",
    "\n",
    "    D, H, W = volume.shape\n",
    "\n",
    "    stride_d, stride_h, stride_w = stride\n",
    "\n",
    "    overlap_d, overlap_h, overlap_w = size_d - stride_d, size_h - stride_h, size_w - stride_w\n",
    "\n",
    "    if padding:\n",
    "        d_pad = (size_d - overlap_d) - ((D - overlap_d) % (size_d - overlap_d))\n",
    "        h_pad = (size_h - overlap_h) - ((H - overlap_h) % (size_h - overlap_h))\n",
    "        w_pad = (size_w - overlap_w) - ((W - overlap_w) % (size_w - overlap_w))\n",
    "        volume = np.pad(volume, ((0, d_pad), (0, h_pad), (0, w_pad)), mode='constant', constant_values=0)\n",
    "        mask = np.pad(mask, ((0, d_pad), (0, h_pad), (0, w_pad)), mode='constant', constant_values=0)\n",
    "\n",
    "    d_steps = int(np.ceil( (D - overlap_d)/(size_d - overlap_d) ))\n",
    "    h_steps = int(np.ceil( (H - overlap_h)/(size_h - overlap_h) ))\n",
    "    w_steps = int(np.ceil( (W - overlap_w)/(size_w - overlap_w) ))\n",
    "    # print(d_steps, h_steps, w_steps)\n",
    "    \n",
    "    out_volume = []\n",
    "    out_mask = []\n",
    "    step_d = 0\n",
    "    done_d = False\n",
    "    while not done_d:\n",
    "        # Depth direction\n",
    "        start_d = step_d * (size_d - overlap_d)\n",
    "        if start_d < 0: start_d = 0\n",
    "        end_d = start_d + size_d\n",
    "        if end_d >= D:\n",
    "            done_d = True\n",
    "        if end_d > D and not padding:\n",
    "            continue\n",
    "        # print(overlap_d, start_d, end_d)\n",
    "        done_h = False\n",
    "        step_h = 0\n",
    "        while not done_h:\n",
    "            # Height direction\n",
    "            start_h = step_h * (size_h - overlap_h)\n",
    "            if start_h < 0: start_h = 0\n",
    "            end_h = start_h + size_h\n",
    "            if end_h >= H:\n",
    "                done_h = True\n",
    "            if end_h > H and not padding:\n",
    "                continue\n",
    "            done_w = False\n",
    "            step_w = 0\n",
    "            while not done_w:\n",
    "                # Width derection\n",
    "                start_w = step_w * (size_w - overlap_w)\n",
    "                if start_w < 0: start_w = 0\n",
    "                end_w = start_w + size_w\n",
    "                if end_w >= W:\n",
    "                    done_w = True\n",
    "                if end_w > W and not padding:\n",
    "                    continue\n",
    "                # print(f'{start_d}:{end_d}, {start_h}:{end_h}, {start_w}:{end_w}')\n",
    "                vol_voxel = volume[start_d:end_d, start_h:end_h, start_w:end_w]\n",
    "                mask_voxel = mask[start_d:end_d, start_h:end_h, start_w:end_w]\n",
    "                if vol_voxel.shape[0] != ch:\n",
    "                    vol_voxel = np.expand_dims(vol_voxel, axis=0)\n",
    "                    mask_voxel = np.expand_dims(mask_voxel, axis=0)\n",
    "                if remove:\n",
    "                    if np.count_nonzero(mask_voxel) / np.count_nonzero(np.ones_like(mask_voxel)) > percent:\n",
    "                        out_volume.append(vol_voxel)\n",
    "                        out_mask.append(mask_voxel)\n",
    "                    else:\n",
    "                        remove_patch += 1\n",
    "                else:\n",
    "                    out_volume.append(vol_voxel)\n",
    "                    out_mask.append(mask_voxel)\n",
    "                step_w += 1\n",
    "            step_h += 1\n",
    "        step_d += 1\n",
    "    # print(step_h, step_w, step_d)\n",
    "    print(f\"The number of removed patchs: {remove_patch}\")\n",
    "    if len(out_volume) > 0:\n",
    "        return np.stack(out_volume), np.stack(out_mask)\n",
    "    return np.array([], dtype=np.float32), np.array([], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "prZAvxMjOIib"
   },
   "source": [
    "# Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o3gwVsNE1sHb"
   },
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "\n",
    "HU_MIN = -100\n",
    "HU_MAX = 400\n",
    "\n",
    "def scale_to_0_1(arr):\n",
    "    return (arr - arr.min()) / (arr.max() - arr.min())\n",
    "\n",
    "def preprocess(volume, mask, AD_filter=False):\n",
    "    # HU window and scale to [0, 1]\n",
    "    volume = np.clip(volume, HU_MIN, HU_MAX)\n",
    "    volume = scale_to_0_1(volume)\n",
    "    mask = np.clip(mask, 0, 1)\n",
    "    \n",
    "    #Anisotropic Diffusion Filter\n",
    "    if AD_filter:\n",
    "        image_itk2 = sitk.GetImageFromArray(volume, isVector=False)\n",
    "        AD_filter = sitk.CurvatureAnisotropicDiffusionImageFilter()\n",
    "        AD_filter.SetTimeStep(0.0625)\n",
    "        AD_filter.SetNumberOfIterations(4)\n",
    "        AD_filter.SetConductanceParameter(1.5)\n",
    "        image_itk2 = AD_filter.Execute(image_itk2)\n",
    "        volume = sitk.GetArrayFromImage(image_itk2)\n",
    "    \n",
    "    volume = scale_to_0_1(volume)\n",
    "    \n",
    "    return volume, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q_pMGgKgOLR6"
   },
   "source": [
    "# Gen pre-training data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K9ZnLAl6TJzk"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "prevol_dir  = '/workspace/dataset/data_pretrain/VOLUME'\n",
    "premask_dir = '/workspace/dataset/data_pretrain/VESSEL'\n",
    "\n",
    "vol_path = Path(prevol_dir)\n",
    "mask_path = Path(premask_dir)\n",
    "if vol_path.exists():\n",
    "    rm_tree(vol_path.parent)\n",
    "\n",
    "vol_path.mkdir(parents=True)\n",
    "mask_path.mkdir(parents=True)\n",
    "del vol_path, mask_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "odmOETqa89NX"
   },
   "outputs": [],
   "source": [
    "def preprocess(vol, mask, minv, maxv):\n",
    "    vol = np.clip(vol, minv, maxv)\n",
    "    vol = (vol - minv)/ (maxv - minv)\n",
    "    mask = np.clip(mask, 0, 1)\n",
    "    return vol, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 616063,
     "status": "ok",
     "timestamp": 1599276977065,
     "user": {
      "displayName": "tung thanh",
      "photoUrl": "",
      "userId": "15694465576135319241"
     },
     "user_tz": -420
    },
    "id": "AkObmF8uTK1p",
    "outputId": "31b1cd47-d81a-4cee-8eaa-cded46d99dc5"
   },
   "outputs": [],
   "source": [
    "pth = '/workspace/dataset/3dircadb_zoom_crop/Zoom_Crop_05'\n",
    "size = (1, 64, 96, 96)\n",
    "stride = (32, 32, 32)\n",
    "\n",
    "lst_test = [0, 3, 5, 10, 16, 18]\n",
    "n = 0\n",
    "for idx in range(20):\n",
    "    if idx in lst_test:\n",
    "        continue\n",
    "    volume_path = pth + f'/VOLUME/volume_{idx}.pth'\n",
    "    mask_path   = pth + f'/VESSEL/volume_{idx}.pth'\n",
    "    img_ori  = torch.load(volume_path)\n",
    "    mask_ori = torch.load(mask_path)\n",
    "    print(f'# Load volume {idx} ---> Shape of volume: ', img_ori.shape)\n",
    "    \n",
    "    img_ori, mask_ori = preprocess(img_ori, mask_ori, -100, 400)\n",
    "    img, mask = generate_patches(img_ori, mask_ori, size=size, stride=stride, \n",
    "                                 padding=True, remove=True, percent=0.001)\n",
    "    \n",
    "    print(f'-- Done volume {idx} -- {img.shape}')\n",
    "    \n",
    "    torch.save(img,  prevol_dir + f'/volume_{n}.pth')\n",
    "    torch.save(mask, premask_dir + f'/volume_{n}.pth')\n",
    "\n",
    "    del img, mask, img_ori, mask_ori\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VoDulf3BJr3e"
   },
   "source": [
    "# Augment training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q24DMMiazGhe"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "folder_train = 'data/train'\n",
    "vol_dir = f'/workspace/dataset/{folder_train}/volumes'\n",
    "mask_dir = f'/workspace/dataset/{folder_train}/masks'\n",
    "# the number of training patient\n",
    "n = 14\n",
    "# n sampling augmentation\n",
    "n_sampling = 1\n",
    "\n",
    "vol_path = Path(vol_dir)\n",
    "mask_path = Path(mask_dir)\n",
    "vol_path.mkdir(parents=True, exist_ok=True)\n",
    "mask_path.mkdir(parents=True, exist_ok=True)\n",
    "del vol_path, mask_path\n",
    "\n",
    "rnd_state = np.random.RandomState(24)\n",
    "\n",
    "VOL_SIZE  = (64, 96, 96)\n",
    "MASK_SIZE = VOL_SIZE\n",
    "\n",
    "# Aug setting\n",
    "ROTATE_PROB = 0.5\n",
    "ELASTIC_PROB = 0.3\n",
    "MAX_ROTATE_ANGLE_X = 10\n",
    "MAX_ROTATE_ANGLE_Y = 10\n",
    "MAX_ROTATE_ANGLE_Z = 45\n",
    "\n",
    "data_pretrain_path = 'data_pretrain'\n",
    "prevol_dir = f'/workspace/dataset/{data_pretrain_path}/VOLUME'\n",
    "premask_dir = f'/workspace/dataset/{data_pretrain_path}/VESSEL'\n",
    "\n",
    "fg_mean = []\n",
    "count = 0\n",
    "buffer = 400\n",
    "for i in range(n):\n",
    "    volumes = torch.load(prevol_dir + f'/volume_{i}.pth') # numpy array\n",
    "    masks = torch.load(premask_dir + f'/volume_{i}.pth')\n",
    "    print(f\"Patient #{i}\", volumes.shape)\n",
    "    for idx in range(masks.shape[0]):\n",
    "        vol = volumes[idx,0]\n",
    "        mask = masks[idx,0]\n",
    "\n",
    "        if rnd_state.random_sample() < 0.4:     \n",
    "            vol_crop = vol.copy()\n",
    "            mask_crop = mask.copy()\n",
    "\n",
    "            fg = np.count_nonzero(mask_crop) / np.count_nonzero(np.ones_like(mask_crop))\n",
    "            fg_mean.append(fg)\n",
    "        \n",
    "            vol_crop = torch.from_numpy(vol_crop.copy())\n",
    "            vol_crop = vol_crop.unsqueeze_(0)\n",
    "            mask_crop = torch.from_numpy(mask_crop.copy())\n",
    "            mask_crop = mask_crop.unsqueeze_(0)\n",
    "\n",
    "            index_file = count // buffer\n",
    "            frag_vol  = Path(vol_dir  + f'/data{index_file}')\n",
    "            frag_mask = Path(mask_dir + f'/data{index_file}')\n",
    "            frag_vol.mkdir(parents=True, exist_ok=True)\n",
    "            frag_mask.mkdir(parents=True, exist_ok=True)\n",
    "            torch.save(vol_crop,  vol_dir  + f'/data{index_file}/vol_{str(count)}.pth')\n",
    "            torch.save(mask_crop, mask_dir + f'/data{index_file}/vol_{str(count)}.pth')\n",
    "            count += 1 \n",
    "            \n",
    "        for i in range(n_sampling):\n",
    "            if rnd_state.random_sample() < 0.4:     \n",
    "                continue\n",
    "            aug_vol, aug_mask = aug_data(vol, mask)\n",
    "\n",
    "            aug_vol = torch.from_numpy(aug_vol.copy())\n",
    "            aug_vol = aug_vol.unsqueeze_(0)\n",
    "            aug_mask = torch.from_numpy(aug_mask.copy())\n",
    "            aug_mask = aug_mask.unsqueeze_(0)\n",
    "\n",
    "            index_file = count // buffer\n",
    "            frag_vol  = Path(vol_dir  + f'/data{index_file}')\n",
    "            frag_mask = Path(mask_dir + f'/data{index_file}')\n",
    "            frag_vol.mkdir(parents=True, exist_ok=True)\n",
    "            frag_mask.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            torch.save(aug_vol,  vol_dir  + f'/data{index_file}/vol_{str(count)}.pth')\n",
    "            torch.save(aug_mask, mask_dir + f'/data{index_file}/vol_{str(count)}.pth')\n",
    "            count += 1 \n",
    "        # -- end n sampling -- \n",
    "    # -- end 1 patient --\n",
    "x = torch.tensor(count)\n",
    "torch.save(x, f'/workspace/dataset/{folder_train}/info.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ycCxvE4c3rbh"
   },
   "outputs": [],
   "source": [
    "fg_mean = torch.tensor(fg_mean)\n",
    "print(x)\n",
    "print(fg_mean.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1TfRIXLKQH8q"
   },
   "source": [
    "# Load val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YQ99Dlrt_jw2"
   },
   "outputs": [],
   "source": [
    "def scale_to_0_1(arr):\n",
    "    return (arr - arr.min()) / (arr.max() - arr.min())\n",
    "\n",
    "def preprocess(volume, mask, hu_min, hu_max):\n",
    "    volume = np.clip(volume, hu_min, hu_max)\n",
    "    volume = scale_to_0_1(volume)\n",
    "    mask[mask >= 0.5] = 1\n",
    "    mask[mask < 0.5] = 0\n",
    "    return volume, mask\n",
    "\n",
    "def load_all_subvols(subvols_path, sub_vol_shape, sub_vol_type=torch.float32):\n",
    "    n_subvols = int(torch.load(subvols_path + 'num.pth'))\n",
    "    subvols = torch.empty(eval('(n_subvols, )') + sub_vol_shape[-3:], dtype=sub_vol_type)\n",
    "    for i in range(0, n_subvols):\n",
    "        subvols[i] = torch.load(subvols_path + f'vol_{i}.pth').to(sub_vol_type)\n",
    "    return subvols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hj_y60ixwuIb"
   },
   "outputs": [],
   "source": [
    "def generate_patches(volume, mask, size=(64, 192, 192), stride=(64, 192, 192), padding=False, remove=True, number=10):\n",
    "    \"\"\"\n",
    "    volume, mask: numpy array (D, H, W)\n",
    "    size: shape of an output patch \n",
    "    @return numpy array (n, c, h, w) or (n, 1, d, h, w)\n",
    "    \"\"\"\n",
    "    assert volume.shape == mask.shape, 'Shape of volume and mask are different'\n",
    "    assert len(volume.shape) == 3, 'Invalid volume shape'\n",
    "    assert len(size) == 3, 'Invalid size'\n",
    "    assert len(stride) == 3, 'Invalid stride'\n",
    "    remove_patch = 0\n",
    "    size_d, size_h, size_w = size\n",
    "    channels = 1 # Fixed\n",
    "\n",
    "    D, H, W = volume.shape\n",
    "\n",
    "    stride_d, stride_h, stride_w = stride\n",
    "\n",
    "    overlap_d, overlap_h, overlap_w = size_d - stride_d, size_h - stride_h, size_w - stride_w\n",
    "\n",
    "    if padding:\n",
    "        d_pad = (size_d - overlap_d) - ((D - overlap_d) % (size_d - overlap_d))\n",
    "        h_pad = (size_h - overlap_h) - ((H - overlap_h) % (size_h - overlap_h))\n",
    "        w_pad = (size_w - overlap_w) - ((W - overlap_w) % (size_w - overlap_w))\n",
    "        volume = np.pad(volume, ((0, d_pad), (0, h_pad), (0, w_pad)), mode='constant', constant_values=0)\n",
    "        mask = np.pad(mask, ((0, d_pad), (0, h_pad), (0, w_pad)), mode='constant', constant_values=0)\n",
    "\n",
    "    d_steps = int(np.ceil( (D - overlap_d)/(size_d - overlap_d) ))\n",
    "    h_steps = int(np.ceil( (H - overlap_h)/(size_h - overlap_h) ))\n",
    "    w_steps = int(np.ceil( (W - overlap_w)/(size_w - overlap_w) ))\n",
    "    # print(d_steps, h_steps, w_steps)\n",
    "\n",
    "    out_volume = []\n",
    "    out_mask = []\n",
    "    step_d = 0\n",
    "    done_d = False\n",
    "    while not done_d:\n",
    "        # Depth direction\n",
    "        start_d = step_d * (size_d - overlap_d)\n",
    "        if start_d < 0: start_d = 0\n",
    "        end_d = start_d + size_d\n",
    "        if end_d >= D:\n",
    "            done_d = True\n",
    "        if end_d > D and not padding:\n",
    "            continue\n",
    "        # print(overlap_d, start_d, end_d)\n",
    "        done_h = False\n",
    "        step_h = 0\n",
    "        while not done_h:\n",
    "            # Height direction\n",
    "            start_h = step_h * (size_h - overlap_h)\n",
    "            if start_h < 0: start_h = 0\n",
    "            end_h = start_h + size_h\n",
    "            if end_h >= H:\n",
    "                done_h = True\n",
    "            if end_h > H and not padding:\n",
    "                continue\n",
    "            done_w = False\n",
    "            step_w = 0\n",
    "            while not done_w:\n",
    "                # Width derection\n",
    "                start_w = step_w * (size_w - overlap_w)\n",
    "                if start_w < 0: start_w = 0\n",
    "                end_w = start_w + size_w\n",
    "                if end_w >= W:\n",
    "                    done_w = True\n",
    "                if end_w > W and not padding:\n",
    "                    continue\n",
    "                # print(f'{start_d}:{end_d}, {start_h}:{end_h}, {start_w}:{end_w}')\n",
    "                vol_voxel = volume[start_d:end_d, start_h:end_h, start_w:end_w]\n",
    "                mask_voxel = mask[start_d:end_d, start_h:end_h, start_w:end_w]\n",
    "                if vol_voxel.shape[0] != channels:\n",
    "                    vol_voxel = np.expand_dims(vol_voxel, axis=0)\n",
    "                    mask_voxel = np.expand_dims(mask_voxel, axis=0)\n",
    "\n",
    "                if remove:\n",
    "                    if np.sum(mask_voxel) > number:\n",
    "                        out_volume.append(vol_voxel)\n",
    "                        out_mask.append(mask_voxel)\n",
    "                    else:\n",
    "                        remove_patch += 1\n",
    "                else:\n",
    "                    out_volume.append(vol_voxel)\n",
    "                    out_mask.append(mask_voxel)\n",
    "                step_w += 1\n",
    "            step_h += 1\n",
    "        step_d += 1\n",
    "    # print(step_h, step_w, step_d)\n",
    "    # print(f\"The number of removed patchs: {remove_patch}\")\n",
    "    if len(out_volume) > 0:\n",
    "        return np.stack(out_volume), np.stack(out_mask)\n",
    "    return np.array([], dtype=np.float32), np.array([], dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o7OP-rpLwuCa"
   },
   "outputs": [],
   "source": [
    "SUB_VOL_SIZE = (64, 96, 96)\n",
    "PTH_DIR = '/workspace/dataset/3dircadb_zoom_crop/Zoom_Crop_05'\n",
    "SAVE_DIR = f'/workspace/dataset/data/val/'\n",
    "\n",
    "LST_IDX = [5, 16, 18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28558,
     "status": "ok",
     "timestamp": 1599288765879,
     "user": {
      "displayName": "tung thanh",
      "photoUrl": "",
      "userId": "15694465576135319241"
     },
     "user_tz": -420
    },
    "id": "AKkD7CkIwvqc",
    "outputId": "96fd870b-e5cd-42f0-d0c6-dee70d265b4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved patient 5\n",
      "Saved patient 16\n",
      "Saved patient 18\n"
     ]
    }
   ],
   "source": [
    "for i in LST_IDX:\n",
    "    ### Save sub-volume for one volume\n",
    "    patient_idx = i\n",
    "    # 1. Load volume\n",
    "    volume = torch.load(PTH_DIR + '/VOLUME' + f'/volume_{patient_idx}.pth')\n",
    "    mask = torch.load(PTH_DIR + '/VESSEL' + f'/volume_{patient_idx}.pth')\n",
    "    # 2. Preprocess\n",
    "    volume, mask = preprocess(volume, mask, -100, 400)\n",
    "    # 3. Generate sub-volume from volume\n",
    "    sub_vols, _ = generate_patches(volume, mask, size=SUB_VOL_SIZE, stride=SUB_VOL_SIZE, padding=True, remove=False)\n",
    "    # 4. Save all sub-volume to file\n",
    "    for i in range(sub_vols.shape[0]):\n",
    "        pth_vol = torch.from_numpy(sub_vols[i])\n",
    "        # Make save path\n",
    "        save_vol_path = SAVE_DIR + f'patient_{patient_idx}/'\n",
    "        vol_path = Path(save_vol_path)\n",
    "        vol_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        torch.save(pth_vol, save_vol_path  + f'vol_{i}.pth')\n",
    "    torch.save(sub_vols.shape[0], save_vol_path + f'num.pth')\n",
    "    torch.save(sub_vols[0].shape, save_vol_path+ f'shape.pth')\n",
    "    # 5. Save mask\n",
    "    torch.save(torch.from_numpy(mask), save_vol_path + f'mask.pth')\n",
    "    print(f'Saved patient {patient_idx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pyy8EEQdyhd7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "S0eQ0Gj9QFJW",
    "rcTE-6Q9X-P5",
    "4O3XwTBCNa5M",
    "bvO4O44JpqoA",
    "prZAvxMjOIib"
   ],
   "machine_shape": "hm",
   "name": "Gen_Data3D_Vessel.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
